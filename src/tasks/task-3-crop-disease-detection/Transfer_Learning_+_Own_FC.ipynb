{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning + Own FC.ipynb",
      "provenance": [],
      "mount_file_id": "1YS0dblOH63232Px3FtQF5u0S3sNN2O1I",
      "authorship_tag": "ABX9TyNOz47EOstr4jbuPdy5sYS/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cv83RUONiqcu"
      },
      "source": [
        "## Transfer Learning\n",
        "*This notebook is for creating a model to predict the crop diseases using transfer learning*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9fwkMCvjlFw"
      },
      "source": [
        "Steps to build our model.\n",
        "\n",
        "1.   Image Preprocessing\n",
        "      * Convert to array\n",
        "\n",
        "2.   Image Augmentation using Keras Image Data Generator\n",
        "3.   Model Building\n",
        "      * Use Transfer Learning models like VGG16, Xception, MobileVNet, etc.\n",
        "\n",
        "*Create a function that will allow us to run the model over and over again to check for optimal parameters*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDUUrizUVTkK"
      },
      "source": [
        "## Image Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juRpNVMvVC7Q"
      },
      "source": [
        "import cv2\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9Sh4LH0VRRK"
      },
      "source": [
        "def preprocess(image):\n",
        "  img = cv2.GaussianBlur(image,(5,5),0)\n",
        "  return img_to_array(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqcHJbHXVkR-"
      },
      "source": [
        "## Image Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xUcKGHGX5tS"
      },
      "source": [
        "# VARIABLES\n",
        "\n",
        "TARGET_SIZE = (224, 224)\n",
        "BATCH_SIZE = 50\n",
        "EPOCHS = 40\n",
        "\n",
        "LEARNING_RATE = 1e-4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUMrmRsXX1zC"
      },
      "source": [
        "train_path = '/content/drive/MyDrive/Omdena/Osun Nigeria/Data/Maize Images/data/train'\n",
        "test_path = '/content/drive/MyDrive/Omdena/Osun Nigeria/Data/Maize Images/data/test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UxSYEgiYabj"
      },
      "source": [
        "train_generator = ImageDataGenerator(rescale=1.0/255,\n",
        "                             rotation_range=30,\n",
        "                             width_shift_range=0.3,\n",
        "                             height_shift_range=0.3,\n",
        "                             zoom_range=0.2,\n",
        "                             shear_range=0.3,\n",
        "                             horizontal_flip=True,\n",
        "                             brightness_range=[0.2, 0.8],\n",
        "                             validation_split=0.2,\n",
        "                             preprocessing_function=preprocess)\n",
        "\n",
        "valid_generator = ImageDataGenerator(rescale=1./255,\n",
        "                                     validation_split = 0.2,\n",
        "                                   preprocessing_function=preprocess)\n",
        "\n",
        "test_generator = ImageDataGenerator(rescale=1./255,\n",
        "                                   preprocessing_function=preprocess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_WMAcEzVpCc"
      },
      "source": [
        "def augment_images(datagen, directory, batch_size, target_size, subset=None):\n",
        "  augmented_imgs = datagen.flow_from_directory(directory = directory,\n",
        "                                                    target_size = TARGET_SIZE,\n",
        "                                                    batch_size = BATCH_SIZE,\n",
        "                                                    subset = subset)\n",
        "  return augmented_imgs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CFvnmKsXr3O",
        "outputId": "94aab64d-44be-47d7-d76f-632442902359"
      },
      "source": [
        "train_aug = augment_images(train_generator, train_path, BATCH_SIZE, TARGET_SIZE, 'training')\n",
        "valid_aug = augment_images(valid_generator, train_path, BATCH_SIZE, TARGET_SIZE, 'validation')\n",
        "test_aug = augment_images(test_generator, test_path, BATCH_SIZE, TARGET_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2681 images belonging to 4 classes.\n",
            "Found 667 images belonging to 4 classes.\n",
            "Found 840 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avZxQWdYaWaX"
      },
      "source": [
        "## Model Specification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9flRXdKci0_"
      },
      "source": [
        "from tensorflow.keras.applications import VGG16, Xception\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout  \n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGLS8-g_ebqB"
      },
      "source": [
        "vgg_model = VGG16(input_shape=(224, 224, 3), weights=\"imagenet\", include_top=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHHhnFjYjS5J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65108763-b783-47ae-9528-c19ed85e5fc8"
      },
      "source": [
        "xception_model = Xception(input_shape=(224, 224, 3), weights=\"imagenet\", include_top=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n",
            "83697664/83683744 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INjAjXLFaZbT"
      },
      "source": [
        "def build_model(pretrained_model):\n",
        "\n",
        "  for layer in pretrained_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(pretrained_model)\n",
        "\n",
        "  #Adding our own classifier\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer=Adam(learning_rate = LEARNING_RATE), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDIGL5f0ju80"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "def train_model(model, name):\n",
        "\n",
        "  checkpoint = ModelCheckpoint(f'/content/drive/MyDrive/Omdena/Osun Nigeria/Model/weights_{name}.hdf5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "  stop = EarlyStopping(monitor=\"val_loss\", patience=4)\n",
        "\n",
        "  history = model.fit(train_aug,\n",
        "                    steps_per_epoch=len(train_aug)//BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=valid_aug,\n",
        "                    verbose=2,\n",
        "                    shuffle=True,\n",
        "                    callbacks = [checkpoint])\n",
        "  return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2QwN9Wzk3u_"
      },
      "source": [
        "xcep_hist = train_model(build_model(xception_model), 'xception_rf')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}