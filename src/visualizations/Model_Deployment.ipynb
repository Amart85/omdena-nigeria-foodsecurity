{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OOP - Model Deployment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Zj2JosWw3dEbWUUVCZWGMVgopIyXrg8u",
      "authorship_tag": "ABX9TyPxO5jHNY5qmOMdZfyWT2dp"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "orwu3D8Yjvm1"
      },
      "source": [
        "!pip install streamlit\n",
        "!pip install streamlit-folium\n",
        "!pip install geopandas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8O1OtTcAl9Uc",
        "outputId": "2ca6c082-c6c4-4229-861f-6223c26b7312"
      },
      "source": [
        "import os\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/Omdena/Osun Nigeria/OOP_App')\n",
        "\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Omdena/Osun Nigeria/OOP_App\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-y8EM9QokOLT",
        "outputId": "354504d6-a191-4a5c-eda8-dd4a90dee388"
      },
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "from apps import home, crop_disease_detector, crop_detector, weather_predictor\n",
        "from PIL import Image\n",
        "\n",
        "with st.container():\n",
        "    proj_title_col, logo_col = st.columns([6,1])\n",
        "\n",
        "    with proj_title_col:\n",
        "      st.header('Improving Food Security and Crop Yield in Nigeria using Machine Learning')\n",
        "\n",
        "    with logo_col:\n",
        "      logo = Image.open('/content/drive/MyDrive/Omdena/Osun Nigeria/App/osun_chapter.png')\n",
        "      logo = logo.resize((75,75))\n",
        "      st.image(logo)\n",
        "\n",
        "PAGES = {\n",
        "    \"Home\": home,\n",
        "    \"Crop Disease Detection\": crop_disease_detector,\n",
        "    'Crop Classification': crop_detector,\n",
        "    'Weather Forecast': weather_predictor\n",
        "}\n",
        "\n",
        "selection = st.sidebar.radio(\"Menu\", list(PAGES.keys()))\n",
        "page = PAGES[selection]\n",
        "page.app()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgQQVlqqkyf6",
        "outputId": "ffdaddc4-ccc3-4093-8bc5-f122a7064f08"
      },
      "source": [
        "%%writefile apps/home.py\n",
        "\n",
        "import streamlit as st\n",
        "\n",
        "def app():\n",
        "  st.subheader('Problem Statement')\n",
        "  st.write(\"According to the Food and Agriculture Organisation of the United Nations, 2018, \\\n",
        "  approximately 88 % of the farmers in Nigeria engage in \\\n",
        "  agricultural production at a subsistence level, and they lack sustainable \\\n",
        "  farming knowledge and practices. Also, Nigeria is endowed with \\\n",
        "  different climatic conditions and soil quality which leads to lackluster \\\n",
        "  crop production. \")\n",
        "\n",
        "  st.markdown('##')\n",
        "\n",
        "  st.subheader('Objectives of the Project')\n",
        "  st.write('This project is aimed at helping farmers to boost their \\\n",
        "  farm produce and plan their farming system.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting apps/home.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPh6wHG_yc0j",
        "outputId": "ff6dc05a-c225-4be8-faf0-fff36925be50"
      },
      "source": [
        "%%writefile apps/app_detector.py\n",
        "\n",
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import utils\n",
        "\n",
        "class AppDetector:\n",
        "\n",
        "  def __init__(self, data, target_size):\n",
        "    self.data = data\n",
        "    self.target_size = target_size\n",
        "  \n",
        "\n",
        "  def app(self):\n",
        "    #new_image = ''\n",
        "    has_pred = False\n",
        "    has_replaced_image = False\n",
        "    #pred = ''\n",
        "\n",
        "    model = utils.load_model(self.data)\n",
        "\n",
        "    \n",
        "    with st.container():\n",
        "        upload_col, predict_col = st.columns([6,1])\n",
        "        with upload_col:\n",
        "          \n",
        "          #Upload the image\n",
        "          uploaded_file = st.file_uploader('Choose a file',type=[\"jpg\", 'png'])\n",
        "          if uploaded_file is not None:\n",
        "            img = Image.open(uploaded_file)\n",
        "            img_display = img.resize((700, 500))\n",
        "            st.image(img_display)\n",
        "\n",
        "            #Preprocess image\n",
        "            if self.data == 'Crops':\n",
        "              img = utils.crop_preprocess_img(img, self.target_size)\n",
        "            else:\n",
        "              img = utils.disease_preprocess_img(img, self.target_size)\n",
        "            \n",
        "            new_image = img\n",
        "            has_replaced_image = True\n",
        "            \n",
        "            \n",
        "        with predict_col:\n",
        "          #Predict the disease label for the image\n",
        "            if st.button('Predict'):\n",
        "              if has_replaced_image:\n",
        "                predictions = utils.predict(new_image, model)\n",
        "                pred = np.argmax(predictions)\n",
        "                has_pred = True\n",
        "              else:\n",
        "                st.error('Please upload an image')\n",
        "\n",
        "    #This container is for the description of the predicted disease of the image            \n",
        "    with st.container():\n",
        "      if has_pred:\n",
        "        class_ = utils.get_class(self.data, pred)\n",
        "        st.title(class_)\n",
        "        if self.data != 'Crops':\n",
        "          with st.expander(\"Read disease description\"):\n",
        "            #disease = utils.get_class(self.data, pred)\n",
        "            #st.title(disease)\n",
        "            disease_desc = utils.get_description(class_)\n",
        "            st.markdown(disease_desc, unsafe_allow_html=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting apps/app_detector.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJK6tuiz3vrZ",
        "outputId": "29e40874-b0e6-40b7-dcc2-5c420b8a9184"
      },
      "source": [
        "%%writefile apps/crop_disease_detector.py\n",
        "\n",
        "import streamlit as st\n",
        "from apps.app_detector import AppDetector\n",
        "\n",
        "TARGET_SIZE = 100\n",
        "\n",
        "def app(): \n",
        "  selection = st.selectbox('Crop Dataset', ('Maize', 'Rice'))\n",
        "  app_detect = AppDetector(selection, TARGET_SIZE)\n",
        "  app_detect.app()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting apps/crop_disease_detector.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7QRxwVy_HCh",
        "outputId": "eae47c03-d838-4240-99c7-20c3386185f2"
      },
      "source": [
        "%%writefile apps/crop_detector.py\n",
        "\n",
        "import streamlit as st\n",
        "from apps.app_detector import AppDetector\n",
        "\n",
        "TARGET_SIZE = 224\n",
        "\n",
        "def app():\n",
        "  app_detect = AppDetector('Crops', TARGET_SIZE)\n",
        "  app_detect.app()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting apps/crop_detector.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr-a1YcGSVBe",
        "outputId": "fa805870-5ccf-490b-8a33-76c6ec408399"
      },
      "source": [
        "%%writefile apps/weather_predictor.py\n",
        "#version 4\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import folium\n",
        "from folium.plugins import BeautifyIcon\n",
        "from streamlit_folium import folium_static\n",
        "import geopandas as gpd\n",
        "import shapely\n",
        "import calendar\n",
        "import branca.colormap as cm\n",
        "\n",
        "@st.cache(persist=True, allow_output_mutation=True)\n",
        "def process_data():\n",
        "  all_three = pd.read_csv('/content/drive/MyDrive/Omdena/Osun Nigeria/OOP_App/csv/temp_pr_spei.csv')\n",
        "  all_three = (gpd.GeoDataFrame(all_three, crs='epsg:4326', geometry= all_three.apply(lambda x: \n",
        "                  shapely.geometry.box(x['lon']-0.25, x['lat']-0.25, x['lon']+0.25, x['lat']+0.25 ), axis=1)))\n",
        "  \n",
        "  spei = pd.read_csv('/content/drive/MyDrive/Omdena/Osun Nigeria/OOP_App/csv/historical_spei_gamma.csv')\n",
        "  spei_grid = gpd.GeoDataFrame(spei,crs='epsg:4326', geometry=spei.apply(lambda x: shapely.geometry.box(x['lon']-0.25, x['lat']-0.25, x['lon']+0.25, x['lat']+0.25 ), axis=1))\n",
        "  \n",
        "  temp = pd.read_csv('/content/drive/MyDrive/Omdena/Osun Nigeria/OOP_App/csv/historical_tmp.csv')\n",
        "  temp_grid = gpd.GeoDataFrame(temp,crs='epsg:4326', geometry=temp.apply(lambda x: shapely.geometry.box(x['lon']-0.25, x['lat']-0.25, x['lon']+0.25, x['lat']+0.25 ), axis=1))\n",
        "\n",
        "  rain = pd.read_csv('/content/drive/MyDrive/Omdena/Osun Nigeria/OOP_App/csv/historical_pr.csv')\n",
        "  rain_grid = gpd.GeoDataFrame(rain,crs='epsg:4326', geometry=rain.apply(lambda x: shapely.geometry.box(x['lon']-0.25, x['lat']-0.25, x['lon']+0.25, x['lat']+0.25 ), axis=1))\n",
        "\n",
        "  return all_three, temp_grid, rain_grid, spei_grid\n",
        "\n",
        "def app():\n",
        "  all_three, temp, rain, spei = process_data()\n",
        "\n",
        "  gdf = all_three.copy()\n",
        "  temp = temp.copy()\n",
        "  rain = rain.copy()\n",
        "  spei = spei.copy()\n",
        "\n",
        "  x = all_three['lon'].median()\n",
        "  y = all_three['lat'].median()\n",
        "\n",
        "\n",
        "  option_dict = {'Temperature':'tmp', 'Rainfall':'pre', 'SPEI':'spei_gamma_03'}\n",
        "\n",
        "  # st.markdown('## Weather and Drought Analysis')\n",
        "\n",
        "  st.write('''## Weather and Drought Analysis\n",
        "\n",
        "\n",
        "  The map below shows the spatial and temporal distribution of Temperature and Rainfall, and also one drought index, \n",
        "  the Standardized Precipitation Evapotranspiration Index (SPEI).\n",
        "\n",
        "\n",
        "  The SPEI is a multiscalar drought index based on climatic data. It can be used for determining the onset, \n",
        "  duration and magnitude of drought conditions with respect to normal conditions in a variety of natural and managed \n",
        "  systems such as crops, ecosystems, rivers, water resources, etc. SPEI is a standardized index. Values is between -1 and -2\n",
        "  are said to mean moderate drought, between -2 and -3 are said to mean severe drought, whereas values lower than -3 are \n",
        "  said to mean extreme drought.\n",
        "\n",
        "\n",
        "  The figures show that the Northern regions are hotter and drier, while the Southern regions are cooler and wetter.\n",
        "  ''')\n",
        "\n",
        "\n",
        "  selected = st.radio('Pick a variable', options=option_dict.keys())\n",
        "\n",
        "  v = option_dict[selected]\n",
        "\n",
        "  if selected == 'Temperature':\n",
        "    color = 'OrRd'\n",
        "  elif selected =='Rainfall':\n",
        "    color = 'Blues'\n",
        "  elif selected == 'SPEI':\n",
        "    color = 'RdYlBu'\n",
        "\n",
        "  mon_annual = st.radio('Select level of aggregation', options = ['Annual', 'Monthly'])\n",
        "\n",
        "  if mon_annual == 'Annual':\n",
        "    if selected in ['Temperature', 'SPEI']:\n",
        "      agg_func = 'mean'\n",
        "    elif selected == 'Rainfall':\n",
        "      agg_func = 'sum'\n",
        "    \n",
        "    temp2 = gdf.groupby(['lat', 'lon'])[[v]].agg(agg_func).merge(gdf[['geometry', 'lat', 'lon']].drop_duplicates(), on=['lat','lon']).reset_index()\n",
        "    temp2.columns = ['division', 'lat', 'lon', v, 'geometry']\n",
        "    \n",
        "    temp2.set_crs(epsg=4326, inplace=True)\n",
        "\n",
        "\n",
        "    m = folium.Map(location=[y,x], zoom_start=6)\n",
        "\n",
        "\n",
        "    choropleth = folium.Choropleth(\n",
        "        geo_data=temp2,\n",
        "        name=\"choropleth\",\n",
        "        data=temp2,\n",
        "        columns=['division',v],\n",
        "        key_on=\"feature.properties.division\",\n",
        "        fill_color=color,\n",
        "        fill_opacity=0.7,\n",
        "        line_opacity=0.1,\n",
        "        legend_name=v,\n",
        "    ).add_to(m)\n",
        "\n",
        "    choropleth.geojson.add_child(\n",
        "        folium.features.GeoJsonTooltip([v])\n",
        "    )\n",
        "\n",
        "    st.write('Annual distribution of '+ selected)\n",
        "    folium_static(m)\n",
        "\n",
        "  elif mon_annual=='Monthly':\n",
        "\n",
        "      month = st.selectbox('Pick a month', calendar.month_name[1:])\n",
        "      \n",
        "      m = folium.Map(location=[y,x], zoom_start=6)\n",
        "\n",
        "\n",
        "      choropleth = folium.Choropleth(\n",
        "          geo_data=gdf.loc[gdf['Month_names']==month].reset_index()[['division', v,'geometry']],\n",
        "          name=\"choropleth\",\n",
        "          data=gdf.loc[gdf['Month_names']==month].reset_index()[['division', v,'geometry']],\n",
        "          columns=['division',v],\n",
        "          key_on=\"feature.properties.division\",\n",
        "          fill_color=color,\n",
        "          fill_opacity=0.7,\n",
        "          line_opacity=0.1,\n",
        "          legend_name=v,\n",
        "      ).add_to(m)\n",
        "\n",
        "      choropleth.geojson.add_child(\n",
        "          folium.features.GeoJsonTooltip([v])\n",
        "      )\n",
        "\n",
        "\n",
        "      st.write(selected + ' for the month of '+ month)\n",
        "      folium_static(m)\n",
        "      \n",
        "\n",
        "\n",
        "  st.header('Analyzing trends in Temperature, rainfall, and SPEI')\n",
        "\n",
        "  st.write('''The Modified Mann Kendall test was used to assess the trend in rainfall, temperature, and SPEI for different months.\n",
        "  The data was prepared for the test by smoothing it with a 50 year moving average and a 10 year time step.\n",
        "  The grid points are colored by the slope, in case of temperature it is change in degree Celsius per decade, for rainfall it is \n",
        "  change in mm per decade, and for spei it is change in SPEI per decade. Grid points that have a significant increase \n",
        "  are marked with a \"+\" sign, and those that have a significant decrease are marked with a \"-\" sign.\n",
        "\n",
        "\n",
        "  The figures show that temperature is increasing in most locations, and rainfall is decreasing. The SPEI is also decreasing\n",
        "  in many locations which means that chances of drought are increasing.''')\n",
        "  st.subheader('Trends in Temperature')\n",
        "\n",
        "  month1 = st.selectbox('Pick a month', calendar.month_name[1:], key='month1-key')\n",
        "  st.write('Trends in Temperature for the month of ' + month1 + ' in degrees Celsius/decade')\n",
        "\n",
        "  m1 = folium.Map(location=[y,x], zoom_start=6)\n",
        "\n",
        "  choropleth = folium.Choropleth(\n",
        "      geo_data=temp.loc[temp['month']==month1, ['division', 'slope', 'geometry']],\n",
        "      name=\"choropleth\",\n",
        "      data=temp.loc[temp['month']==month1,['division', 'slope', 'geometry']],\n",
        "      columns=['division','slope'],\n",
        "      key_on=\"feature.properties.division\",\n",
        "      fill_color='PuOr',\n",
        "      fill_opacity=0.7,\n",
        "      line_opacity=0.1,\n",
        "      legend_name='slope',\n",
        "  ).add_to(m1)\n",
        "\n",
        "\n",
        "  choropleth.geojson.add_child(\n",
        "      folium.features.GeoJsonTooltip(['slope'])\n",
        "  )\n",
        "\n",
        "  for index, row in temp.loc[(temp['month']==month1 )& temp['h'] & (temp['z'] >0)].iterrows():\n",
        "    icon_plus = BeautifyIcon(\n",
        "      icon='plus',\n",
        "      icon_shape=None, \n",
        "      border_color=None, \n",
        "      border_width=0,\n",
        "      background_color='')\n",
        "    folium.Marker(\n",
        "          location=[row['lat'], row['lon']], \n",
        "          icon=icon_plus).add_to(m1)\n",
        "\n",
        "  for index, row in temp.loc[(temp['month']== month1 ) & temp['h'] & (temp['z'] <0)].iterrows():\n",
        "    icon_minus = BeautifyIcon(\n",
        "      icon='minus',\n",
        "      icon_shape=None, \n",
        "      border_color=None, \n",
        "      border_width=0,\n",
        "      background_color='')\n",
        "    folium.Marker(\n",
        "          location=[row['lat'], row['lon']], \n",
        "          icon=icon_minus).add_to(m1)\n",
        "\n",
        "  folium_static(m1)\n",
        "\n",
        "  st.subheader('Trends in Rainfall')\n",
        "  st.write('Trends in Rainfall for the month of ' + month1 + ' in mm/decade')\n",
        "\n",
        "  m2 = folium.Map(location=[y,x], zoom_start=6)\n",
        "\n",
        "  choropleth = folium.Choropleth(\n",
        "      geo_data=temp.loc[rain['month']==month1, ['division', 'slope', 'geometry']],\n",
        "      name=\"choropleth\",\n",
        "      data=temp.loc[rain['month']==month1,['division', 'slope', 'geometry']],\n",
        "      columns=['division','slope'],\n",
        "      key_on=\"feature.properties.division\",\n",
        "      fill_color='PuOr',\n",
        "      fill_opacity=0.7,\n",
        "      line_opacity=0.1,\n",
        "      legend_name='slope',\n",
        "  ).add_to(m2)\n",
        "\n",
        "\n",
        "  choropleth.geojson.add_child(\n",
        "      folium.features.GeoJsonTooltip(['slope'])\n",
        "  )\n",
        "\n",
        "  for index, row in rain.loc[(rain['month']==month1 )& temp['h'] & (temp['z'] >0)].iterrows():\n",
        "    icon_plus = BeautifyIcon(\n",
        "      icon='plus',\n",
        "      icon_shape=None, \n",
        "      border_color=None, \n",
        "      border_width=0,\n",
        "      background_color='')\n",
        "    folium.Marker(\n",
        "          location=[row['lat'], row['lon']], \n",
        "          icon=icon_plus).add_to(m2)\n",
        "\n",
        "  for index, row in rain.loc[(rain['month']==month1 ) & rain['h'] & (rain['z'] <0)].iterrows():\n",
        "    icon_minus = BeautifyIcon(\n",
        "      icon='minus',\n",
        "      icon_shape=None, \n",
        "      border_color=None, \n",
        "      border_width=0,\n",
        "      background_color='')\n",
        "    folium.Marker(\n",
        "          location=[row['lat'], row['lon']], \n",
        "          icon=icon_minus).add_to(m2)\n",
        "\n",
        "  folium_static(m2)\n",
        "\n",
        "\n",
        "  st.subheader('Trends in SPEI')\n",
        "  st.write('Trends in SPEI/decade for the month of ' + month1)\n",
        "\n",
        "  m3 = folium.Map(location=[y,x], zoom_start=6)\n",
        "\n",
        "  choropleth = folium.Choropleth(\n",
        "      geo_data=spei.loc[spei['month']==month1, ['division', 'slope', 'geometry']],\n",
        "      name=\"choropleth\",\n",
        "      data=spei.loc[spei['month']==month1,['division', 'slope', 'geometry']],\n",
        "      columns=['division','slope'],\n",
        "      key_on=\"feature.properties.division\",\n",
        "      fill_color='PuOr',\n",
        "      fill_opacity=0.7,\n",
        "      line_opacity=0.1,\n",
        "      legend_name='slope',\n",
        "  ).add_to(m3)\n",
        "\n",
        "\n",
        "  choropleth.geojson.add_child(\n",
        "      folium.features.GeoJsonTooltip(['slope'])\n",
        "  )\n",
        "\n",
        "  for index, row in spei.loc[(spei['month']==month1 )& spei['h'] & (spei['z'] >0)].iterrows():\n",
        "    icon_plus = BeautifyIcon(\n",
        "      icon='plus',\n",
        "      icon_shape=None, \n",
        "      border_color=None, \n",
        "      border_width=0,\n",
        "      background_color='')\n",
        "    folium.Marker(\n",
        "          location=[row['lat'], row['lon']], \n",
        "          icon=icon_plus).add_to(m3)\n",
        "\n",
        "  for index, row in spei.loc[(spei['month']==month1 ) & spei['h'] & (spei['z'] <0)].iterrows():\n",
        "    icon_minus = BeautifyIcon(\n",
        "      icon='minus',\n",
        "      icon_shape=None, \n",
        "      border_color=None, \n",
        "      border_width=0,\n",
        "      background_color='')\n",
        "    folium.Marker(\n",
        "          location=[row['lat'], row['lon']], \n",
        "          icon=icon_minus).add_to(m3)\n",
        "\n",
        "  folium_static(m3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting apps/weather_predictor.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9-AVuU7fQtW",
        "outputId": "6825043e-40f7-4867-f5f6-8efb7740a152"
      },
      "source": [
        "%%writefile utils.py\n",
        "\n",
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "@st.cache(allow_output_mutation=True)\n",
        "def load_model(dataset):\n",
        "  \"\"\"\n",
        "  Loads the models.\n",
        "  \"\"\"\n",
        "\n",
        "  if dataset == 'Maize':\n",
        "    model = tf.keras.models.load_model('/content/drive/MyDrive/Omdena/Osun Nigeria/Model/model_maize_final.h5')\n",
        "  elif dataset == 'Rice':\n",
        "    model = tf.keras.models.load_model('/content/drive/MyDrive/Omdena/Osun Nigeria/Model/model_rice.h5')\n",
        "  elif dataset == 'Crops':\n",
        "    model = tf.keras.models.load_model('/content/drive/MyDrive/crop_classification.h5')\n",
        "  return model\n",
        "\n",
        "def crop_preprocess_img(image, TARGET_SIZE):\n",
        "  pil_img_rgb = image.convert('RGB') \n",
        "  cv2_img = np.array(pil_img_rgb) #convert PIL Image to cv2 format\n",
        "  #img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #convert BGR to RGB\n",
        "  img = cv2.resize(cv2_img, (TARGET_SIZE, TARGET_SIZE)) #resize the image to (224, 224)\n",
        "  img = img_to_array(img) #convert to numpy array\n",
        "  img = img/255 #normalize the image\n",
        "  img = np.expand_dims(img, axis = 0) #expands dimension to one sample\n",
        "  return img\n",
        "\n",
        "def disease_preprocess_img(image, TARGET_SIZE):\n",
        "  \"\"\" Preprocess the image in the same way the images for model building were processed. \n",
        "  \n",
        "  image: uploaded image\n",
        "\n",
        "  Returns: image preprocessed using resnet50's preprocess_input\n",
        "  \"\"\"\n",
        "\n",
        "  img = image.resize((TARGET_SIZE, TARGET_SIZE))\n",
        "  img = img_to_array(img) #convert to numpy array\n",
        "  img = np.expand_dims(img, axis = 0) #expands dimension to one sample\n",
        "  img = preprocess_input(img) #preprocess function by resnet50\n",
        "  return img\n",
        "\n",
        "def predict(image, model):\n",
        "  \"\"\" Predicts the disease of the image.\n",
        "\n",
        "  image: preprocessed image\n",
        "  model: model for maize or rice leaf disease datasets\n",
        "\n",
        "  Returns: probability for each class/disease\n",
        "  \"\"\"\n",
        "  predictions = model.predict(image)\n",
        "  return predictions\n",
        "\n",
        "def get_class(crop, idx):\n",
        "  \"\"\" Gets the disease label for the predicted image.\n",
        "\n",
        "  crop: crop type - maize or rice\n",
        "  idx: column index of the class with the highest probability in the predictions\n",
        "\n",
        "  Returns: disease label\n",
        "\n",
        "  \"\"\"\n",
        "  if crop == 'Maize':\n",
        "    CLASSES = {\n",
        "        0: 'Blight',\n",
        "        1: 'Common Rust',\n",
        "        2: 'Gray Leaf Spot',\n",
        "        3: 'Healthy'\n",
        "    }\n",
        "  elif crop == 'Rice':\n",
        "    CLASSES = {\n",
        "        0: 'Bacterial Leaf Blight',\n",
        "        1: 'Brown Spot',\n",
        "        2: 'Leaf Smut'\n",
        "    }\n",
        "  elif crop == 'Crops':\n",
        "    CLASSES = {\n",
        "        0: 'Rice',\n",
        "        1: 'Maize'\n",
        "    }\n",
        "\n",
        "  return CLASSES[idx]\n",
        "\n",
        "def get_description(disease):\n",
        "  \"\"\" Gets the disease description\n",
        "\n",
        "    disease: predicted disease for the image\n",
        "  \"\"\"\n",
        "  maize_blight = f\"\"\"\n",
        "  <p> \n",
        "  The tan lesions of northern corn leaf blight are slender and oblong tapering at the ends ranging in size between 1 to 6 inches. </p>\n",
        "  <p>Lesions run parallel to the leaf margins beginning on the lower leaves and moving up the plant. They may coalesce and cover the enter leaf.\n",
        "  </p>\n",
        "  <p>Spores are produced on the underside of the leaf below the lesions giving the appearance of a dusty green fuzz.</p>\n",
        "\n",
        "  <p> <i>Source: https://cals.cornell.edu/field-crops/corn/diseases-corn/</i></p>\n",
        "  \"\"\"\n",
        "\n",
        "  maize_common_rust = f\"\"\"\n",
        "  <p> Common rust is caused by the fungus Puccinia sorghi. </p>\n",
        "  <p>Small, round to elongate brown pustules form on both leaf surfaces and other above ground parts of the plant. </p>\n",
        "  <p>As the pustules mature they become brown to black. If disease is severe, the leaves may yellow and die early\n",
        "  </p>\n",
        "\n",
        "  <p> <i>Source: https://cals.cornell.edu/field-crops/corn/diseases-corn/</i></p>\n",
        "  \"\"\"\n",
        "  maize_gray_leaf_spot = f\"\"\"\n",
        "  <p> Gray leaf spot is caused by the fungus Cercospora zeae-maydis. \n",
        "  Lesions start as a small dot surrounded by yellow halo, and then will elongate over time parallel to the veins becoming pale brown to gray.\n",
        "  </p>\n",
        "\n",
        "  <p> <i>Source: https://cals.cornell.edu/field-crops/corn/diseases-corn/</i></p>\n",
        "  \"\"\"\n",
        "\n",
        "  maize_healthy = f\"\"\"\"\"\"\n",
        "\n",
        "  rice_bacterial_leaf_blight = f\"\"\"\n",
        "  <p> Rice Bacterial Blight is a deadly bacterial disease that is among the most destructive afflictions of cultivated rice (Oryza sativa and O. glaberrima). \n",
        "  In severe epidemics, crop loss may be as high as 75 percent, and millions of hectares of rice are infected annually.\n",
        "  </p>\n",
        "  \"\"\"\n",
        "\n",
        "  rice_brown_spot = f\"\"\"\n",
        "  <p> Brown spot is caused by the fungus Cochliobolus miyabeanus. Also called Helminthosporium leaf spot, it is one of the most prevalent rice diseases. \n",
        "  It is a fungal disease that infects the coleoptile, leaves, leaf sheath, panicle branches, glumes, and spikelets.\n",
        "  </p>\n",
        "  \"\"\"\n",
        "\n",
        "  rice_leaf_smut = f\"\"\"\n",
        "  <p> Leaf smut, caused by the fungus Entyloma oryzae, is a widely distributed, but somewhat minor, disease of rice. \n",
        "  The fungus produces slightly raised, angular, black spots (sori) on both sides of the leaves.\n",
        "  </p>\n",
        "  \"\"\"\n",
        "\n",
        "  dict_description = {\n",
        "      'Blight': maize_blight,\n",
        "      'Common Rust': maize_common_rust,\n",
        "      'Gray Leaf Spot': maize_gray_leaf_spot,\n",
        "      'Healthy': maize_healthy,\n",
        "      'Bacterial Leaf Blight': rice_bacterial_leaf_blight,\n",
        "      'Brown Spot': rice_brown_spot,\n",
        "      'Leaf Smut': rice_leaf_smut\n",
        "  }\n",
        "\n",
        "  return dict_description[disease]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEfSRQWanSlj",
        "outputId": "daad3134-29a6-4fc5-9297-fd434d87c79a"
      },
      "source": [
        " !streamlit run app.py & npx localtunnel --port 8501"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.998s\n",
            "your url is: https://kind-cheetah-83.loca.lt\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.196.100.208:8501\u001b[0m\n",
            "\u001b[0m\n",
            "2021-10-30 14:44:59.419383: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-10-30 14:44:59.419469: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (85423515b07e): /proc/driver/nvidia/version does not exist\n",
            "2021-10-30 14:48:20.860 NumExpr defaulting to 2 threads.\n",
            "2021-10-30 14:56:13.418353: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
          ]
        }
      ]
    }
  ]
}